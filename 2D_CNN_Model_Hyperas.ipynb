{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2D CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Nahel/anaconda3/envs/NN/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "from hyperas import optim\n",
    "from hyperas.distributions import uniform\n",
    "from hyperopt import Trials, STATUS_OK, tpe\n",
    "# https://github.com/maxpumperla/hyperas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.layers import Conv2D\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.utils import np_utils\n",
    "import h5py\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import keras\n",
    "from keras.models import Model, Sequential\n",
    "from keras.utils import np_utils\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Convolution2D, MaxPooling2D\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Data_Prep():\n",
    "    nb_classes = 1\n",
    "    \n",
    "    data = pd.read_csv('./2D_120.csv')\n",
    "\n",
    "    target = data.AGE.copy(deep=True)\n",
    "    data = data.drop(['Unnamed: 0','AGE'],axis=1)\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "    data,target,test_size=0.2,random_state=42)\n",
    "\n",
    "    mm = MinMaxScaler()\n",
    "    X_train = mm.fit_transform(X_train)\n",
    "    X_test  = mm.transform(X_test)\n",
    "\n",
    "    X_train = X_train.reshape(X_train.shape[0], 256, 150, 1)\n",
    "    X_test  = X_test.reshape(X_test.shape[0], 256, 150, 1)\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(X_train, Y_train, X_test, Y_test):\n",
    "\n",
    "    nb_epoch = 15\n",
    "    \n",
    "    #nb_classes = 1\n",
    "\n",
    "    # input image dimensions\n",
    "    #img_rows, img_cols = 256, 150\n",
    "    #img_channels = 1\n",
    "\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Conv2D({{choice([15, 30])}}, \n",
    "                     (5,5), padding='same',\n",
    "                     activation='relu',\n",
    "                    input_shape=X_train.shape[1:]))\n",
    "    #model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    model.add(Conv2D(30, (4,4), padding='same', activation='relu'))\n",
    "    #model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout({{uniform(0, 1)}}))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense({{choice([512, 256])}},activation='relu'))\n",
    "    #model.add(Activation('relu'))\n",
    "    #model.add(Dropout(0.5))\n",
    "    \n",
    "    model.add(Dense(1))\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "    adam = Adam()\n",
    "    model.compile(loss='mean_squared_error',\n",
    "                  optimizer=adam, \n",
    "                  metrics=['mean_squared_error'])\n",
    "\n",
    "    early_stop = EarlyStopping(monitor='val_loss', min_delta=0, patience=2, mode='auto')\n",
    "    \n",
    "    model.fit(X_train, y_train,\n",
    "            batch_size=128,\n",
    "            epochs=nb_epoch,\n",
    "            callbacks=[early_stop], \n",
    "            validation_data=(X_test, y_test))\n",
    "\n",
    "    score, acc = model.evaluate(X_test, y_test, verbose=1)\n",
    "\n",
    "    return {'loss': -acc, 'status': STATUS_OK, 'model': model}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = Data_Prep()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Imports:\n",
      "#coding=utf-8\n",
      "\n",
      "from __future__ import print_function\n",
      "\n",
      "try:\n",
      "    from hyperas import optim\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from hyperas.distributions import uniform\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from hyperopt import Trials, STATUS_OK, tpe\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras.optimizers import Adam\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras.models import Sequential\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras.layers.convolutional import MaxPooling2D\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras.layers import Conv2D\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras.preprocessing.image import ImageDataGenerator\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras.utils import np_utils\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import h5py\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import pandas as pd\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import numpy as np\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import keras\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras.models import Model, Sequential\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras.utils import np_utils\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras.layers import Dense, Dropout, Activation, Flatten\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras.layers import Convolution2D, MaxPooling2D\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras.callbacks import EarlyStopping\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import seaborn as sns\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import matplotlib.pyplot as plt\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from sklearn.model_selection import train_test_split\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from sklearn.preprocessing import MinMaxScaler\n",
      "except:\n",
      "    pass\n",
      "\n",
      ">>> Hyperas search space:\n",
      "\n",
      "def get_space():\n",
      "    return {\n",
      "        'Conv2D': hp.choice('Conv2D', [15, 30]),\n",
      "        'Dropout': hp.uniform('Dropout', 0, 1),\n",
      "        'Dense': hp.choice('Dense', [512, 256]),\n",
      "    }\n",
      "\n",
      ">>> Data\n",
      "  1: \n",
      "  2: nb_classes = 1\n",
      "  3: \n",
      "  4: data = pd.read_csv('./2D_120.csv')\n",
      "  5: \n",
      "  6: target = data.AGE.copy(deep=True)\n",
      "  7: data = data.drop(['Unnamed: 0','AGE'],axis=1)\n",
      "  8: \n",
      "  9: X_train, X_test, y_train, y_test = train_test_split(\n",
      " 10: data,target,test_size=0.2,random_state=42)\n",
      " 11: \n",
      " 12: mm = MinMaxScaler()\n",
      " 13: X_train = mm.fit_transform(X_train)\n",
      " 14: X_test  = mm.transform(X_test)\n",
      " 15: \n",
      " 16: X_train = X_train.reshape(X_train.shape[0], 256, 150, 1)\n",
      " 17: X_test  = X_test.reshape(X_test.shape[0], 256, 150, 1)\n",
      " 18: \n",
      " 19: \n",
      " 20: \n",
      ">>> Resulting replaced keras model:\n",
      "\n",
      "   1: def keras_fmin_fnct(space):\n",
      "   2: \n",
      "   3: \n",
      "   4:     nb_epoch = 15\n",
      "   5:     \n",
      "   6:     #nb_classes = 1\n",
      "   7: \n",
      "   8:     # input image dimensions\n",
      "   9:     #img_rows, img_cols = 256, 150\n",
      "  10:     #img_channels = 1\n",
      "  11: \n",
      "  12:     model = Sequential()\n",
      "  13: \n",
      "  14:     model.add(Conv2D(space['Conv2D'], \n",
      "  15:                      (5,5), padding='same',\n",
      "  16:                      activation='relu',\n",
      "  17:                     input_shape=X_train.shape[1:]))\n",
      "  18:     #model.add(Activation('relu'))\n",
      "  19:     model.add(MaxPooling2D(pool_size=(2, 2)))\n",
      "  20: \n",
      "  21:     model.add(Conv2D(30, (4,4), padding='same', activation='relu'))\n",
      "  22:     #model.add(Activation('relu'))\n",
      "  23:     model.add(MaxPooling2D(pool_size=(2, 2)))\n",
      "  24:     model.add(Dropout(space['Dropout']))\n",
      "  25: \n",
      "  26:     model.add(Flatten())\n",
      "  27:     model.add(Dense(space['Dense'],activation='relu'))\n",
      "  28:     #model.add(Activation('relu'))\n",
      "  29:     #model.add(Dropout(0.5))\n",
      "  30:     \n",
      "  31:     model.add(Dense(1))\n",
      "  32:     model.add(Activation('relu'))\n",
      "  33: \n",
      "  34:     adam = Adam()\n",
      "  35:     model.compile(loss='mean_squared_error',\n",
      "  36:                   optimizer=adam, \n",
      "  37:                   metrics=['mean_squared_error'])\n",
      "  38: \n",
      "  39:     early_stop = EarlyStopping(monitor='val_loss', min_delta=0, patience=2, mode='auto')\n",
      "  40:     \n",
      "  41:     model.fit(X_train, y_train,\n",
      "  42:             batch_size=128,\n",
      "  43:             epochs=nb_epoch,\n",
      "  44:             callbacks=[early_stop], \n",
      "  45:             validation_data=(X_test, y_test))\n",
      "  46: \n",
      "  47:     score, acc = model.evaluate(X_test, y_test, verbose=1)\n",
      "  48: \n",
      "  49:     return {'loss': -acc, 'status': STATUS_OK, 'model': model}\n",
      "  50: \n",
      "Train on 412 samples, validate on 104 samples\n",
      "Epoch 1/15\n",
      "256/412 [=================>............] - ETA: 1:11 - loss: 2380.7034 - mean_squared_error: 2380.7034"
     ]
    }
   ],
   "source": [
    "best_run, best_model, space = optim.minimize(model=model,\n",
    "                                          data=Data_Prep,\n",
    "                                          algo=tpe.suggest,\n",
    "                                          max_evals=2,\n",
    "                                          trials=Trials(),\n",
    "                                          #eval_space=True,  \n",
    "                                          #return_space=True,\n",
    "                                          notebook_name='2D_CNN_Model_Hyperas'\n",
    "                                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.regplot(best_model.predict(X_test), y_test)\n",
    "#sns.plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:NN]",
   "language": "python",
   "name": "conda-env-NN-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
